{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d7381c",
   "metadata": {},
   "source": [
    "# This codebase is a detailed in-depth practice of all output parsers available in LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dd7a3",
   "metadata": {},
   "source": [
    "### 1. Initial import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e258660b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4019f",
   "metadata": {},
   "source": [
    "### 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "23460e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GROQ key\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Setup Langsmith tracking and tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Setup Langchain project\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5144ac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x0000017CC0B2EC90> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000017CC303E350> model_name='llama-3.3-70b-versatile' temperature=1e-08 model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "5c966c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to help developers build applications that utilize large language models (LLMs) more efficiently. It was created to simplify the process of integrating LLMs into various projects, making it easier for developers to focus on building their applications rather than worrying about the complexities of working with these powerful models.\n",
      "\n",
      "LangChain provides a set of tools and APIs that allow developers to interact with LLMs in a more structured and standardized way. This includes features such as:\n",
      "\n",
      "1. **Model management**: LangChain allows developers to easily switch between different LLMs, including popular models like LLaMA, PaLM, and BERT.\n",
      "2. **Prompt engineering**: The framework provides tools to help developers craft effective prompts that elicit the desired responses from the LLMs.\n",
      "3. **Chain management**: LangChain enables developers to create complex workflows, or \"chains,\" that involve multiple LLMs and other components, such as databases or APIs.\n",
      "4. **Memory management**: The framework includes features to manage the memory and state of LLMs, allowing developers to build more efficient and scalable applications.\n",
      "\n",
      "By using LangChain, developers can build a wide range of applications, including:\n",
      "\n",
      "1. **Chatbots**: LangChain can be used to create conversational interfaces that leverage the power of LLMs.\n",
      "2. **Text analysis**: The framework can be applied to tasks such as sentiment analysis, entity recognition, and text classification.\n",
      "3. **Content generation**: LangChain can be used to generate text, images, or other types of content using LLMs.\n",
      "4. **Decision support systems**: The framework can be used to build systems that provide recommendations or predictions based on LLM outputs.\n",
      "\n",
      "Overall, LangChain aims to democratize access to LLMs, making it easier for developers to build innovative applications that leverage the power of these models.\n"
     ]
    }
   ],
   "source": [
    "# Initial result check from model\n",
    "result = model.invoke(\"What is langchain?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4f22e",
   "metadata": {},
   "source": [
    "### 3. Prompt Engineering - Technically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf43cb",
   "metadata": {},
   "source": [
    "#### I am going to use multiple prompt templates to be applied in each output parsers.\n",
    "\n",
    "StringPromptTemplate: This prompt templates are used to format single string and used for simpler inputs.\n",
    "\n",
    "ChatPromptTemplate: This prompt template is used to format a list of messages.\n",
    "\n",
    "MessagesPlaceholder: Adding a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "05d07c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt templates\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "601c7f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the prompt engineer break up with his girlfriend?\n",
      "\n",
      "Because he wanted a more \"specific\" and \"well-defined\" relationship, but she kept giving him \"ambiguous\" and \"open-ended\" responses! Now he's just trying to \"fine-tune\" his dating life.\n"
     ]
    }
   ],
   "source": [
    "# Sample StringPromptTemplate\n",
    "simple_prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "# Chaining\n",
    "chain_simple_prompt = simple_prompt | model\n",
    "\n",
    "# Result\n",
    "response = chain_simple_prompt.invoke({\"topic\": \"Prompt Engineering\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9d6f9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know, Prompt Engineering is like a relationship. You try to craft the perfect prompt, and it's like writing a love letter. But sometimes, the AI just interprets it in a way that's like, 'I said I love you, not I love pineapples on pizza!' (laughs)\n",
      "\n",
      "I mean, have you ever tried to get an AI to do what you want? It's like trying to get a cat to do tricks for treats. You're like, 'Okay, I'll give you a cookie if you just generate a simple text...' And the AI is like, 'Sure, here's a 10-page essay on the history of cookies...' (laughs)\n",
      "\n",
      "But seriously, Prompt Engineering is an art. It's like trying to solve a puzzle while blindfolded and being attacked by a swarm of bees. You're like, 'I think I've got it... nope, just got stung again!' (laughs)\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate\n",
    "chat_prompt =   ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are best standup comedian of world.\"),\n",
    "        (\"user\", \"Tell me a joke about {topic}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chaining\n",
    "chain_chat = chat_prompt | model\n",
    "\n",
    "# Result\n",
    "response = chain_chat.invoke({\"topic\": \"Prompt Engineering\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "de3c1b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is 'Berlin'.\n"
     ]
    }
   ],
   "source": [
    "# MessagesPlaceHolder\n",
    "message_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a very good student of Geography who has knowledge of all countries and their capital names\"),\n",
    "        MessagesPlaceholder(\"msgs\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Conversation history\n",
    "messages_to_pass = [\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content= \"The capital of France is 'Paris',\"),\n",
    "    HumanMessage(content=\"And what about Germany?\")\n",
    "]\n",
    "\n",
    "# Chaining\n",
    "chain_messages = message_prompt | model\n",
    "\n",
    "# Result\n",
    "response = chain_messages.invoke({\"msgs\": messages_to_pass})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53f147",
   "metadata": {},
   "source": [
    "### 4. Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da7f09",
   "metadata": {},
   "source": [
    "String:  Output parser that parses the LLM result into string format.\n",
    "\n",
    "JSON: Output parser that parses the LLM result into JSON format.\n",
    "\n",
    "XML: Output parser that parses the LLM result into XML format.\n",
    "\n",
    "CSV: Output parser that parses the LLM result into CSV format.\n",
    "\n",
    "Output Fixing parser: Wraps another output parser. If the output has some parsing error, it passes the error and the bad output to LLM and tell it to fix it.\n",
    "\n",
    "RetryWithError: Along with Output fixing parser, it will also send the original instructions.\n",
    "\n",
    "Pydantic: Takes a user defined Pydantic model and returns data in that format.\n",
    "\n",
    "YAML: Takes user defined Pydantic model and returns data in that format. Uses YAML to encode it.\n",
    "\n",
    "PandasDataframe: Useful for doing operations with Pandas dataframe.\n",
    "\n",
    "Enum: Parses response into one of the provided enum values.\n",
    "\n",
    "Datetime: Parses response into a datetime string.\n",
    "\n",
    "Structured: Returns structured information.\n",
    "\n",
    "**All parsers will be attempted mostly with simple prompt template and Chat prompt template.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "caecf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary parsers\n",
    "\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.output_parsers.json import JsonOutputParser\n",
    "from langchain_core.output_parsers.xml import XMLOutputParser\n",
    "from langchain_core.output_parsers.list import CommaSeparatedListOutputParser\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from langchain.output_parsers.retry import RetryWithErrorOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain.output_parsers.pandas_dataframe import PandasDataFrameOutputParser\n",
    "from langchain.output_parsers.datetime import DatetimeOutputParser\n",
    "from langchain.output_parsers.structured import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c17f9",
   "metadata": {},
   "source": [
    "##### 4.1.1. With StringPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c1da05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the object\n",
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "f500d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt templates\n",
    "\n",
    "simple_prompt_str = PromptTemplate(\n",
    "    template=\"You are the best AI Engineer of the world. Answer the query \\n {query} \\n\",\n",
    "    input_variables=[\"query\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_str = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI engineer of the world. Please response to the user as per query from user in normal string format.\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb8f06",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "5313e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the best AI Engineer in the world, I'm delighted to share my expertise on Prompt Engineering.\n",
      "\n",
      "**What is Prompt Engineering?**\n",
      "\n",
      "Prompt Engineering is a subfield of Artificial Intelligence (AI) and Natural Language Processing (NLP) that focuses on designing, optimizing, and fine-tuning the input prompts or queries that are used to interact with language models, chatbots, or other AI systems. The goal of Prompt Engineering is to craft high-quality prompts that elicit specific, accurate, and relevant responses from the AI system.\n",
      "\n",
      "**Why is Prompt Engineering important?**\n",
      "\n",
      "Prompt Engineering is crucial because the quality of the input prompt significantly impacts the quality of the output response. A well-designed prompt can:\n",
      "\n",
      "1. **Improve accuracy**: By providing clear and concise context, a good prompt can help the AI system understand the intent and scope of the query, leading to more accurate responses.\n",
      "2. **Increase relevance**: A well-crafted prompt can guide the AI system to provide responses that are relevant to the user's needs, reducing the likelihood of irrelevant or off-topic answers.\n",
      "3. **Enhance user experience**: By optimizing prompts, developers can create more intuitive and user-friendly interfaces, making it easier for users to interact with AI systems and achieve their goals.\n",
      "4. **Reduce errors**: Poorly designed prompts can lead to errors, misinterpretations, or even biased responses. Prompt Engineering helps mitigate these risks by ensuring that prompts are clear, concise, and unbiased.\n",
      "\n",
      "**Key aspects of Prompt Engineering:**\n",
      "\n",
      "1. **Prompt design**: Crafting prompts that are clear, concise, and well-structured, taking into account the AI system's capabilities and limitations.\n",
      "2. **Prompt optimization**: Refining prompts through iterative testing and refinement to improve response quality and accuracy.\n",
      "3. **Contextual understanding**: Ensuring that prompts provide sufficient context for the AI system to understand the user's intent and scope.\n",
      "4. **Ambiguity resolution**: Designing prompts that minimize ambiguity and clarify any potential uncertainties.\n",
      "5. **Evaluation metrics**: Developing metrics to assess the effectiveness of prompts and the quality of responses.\n",
      "\n",
      "**Techniques used in Prompt Engineering:**\n",
      "\n",
      "1. **Prompt templating**: Creating reusable prompt templates that can be adapted for different use cases.\n",
      "2. **Prompt augmentation**: Adding additional context or information to prompts to improve response quality.\n",
      "3. **Adversarial testing**: Testing prompts with adversarial examples to identify potential weaknesses and improve robustness.\n",
      "4. **Human evaluation**: Involving human evaluators to assess the quality and relevance of responses.\n",
      "5. **Automated prompt optimization**: Using machine learning algorithms to optimize prompts and improve response quality.\n",
      "\n",
      "**Applications of Prompt Engineering:**\n",
      "\n",
      "1. **Chatbots and virtual assistants**: Designing effective prompts to improve user experience and response accuracy.\n",
      "2. **Language translation**: Crafting prompts that help language models produce more accurate and fluent translations.\n",
      "3. **Text summarization**: Optimizing prompts to generate concise and informative summaries.\n",
      "4. **Question answering**: Developing prompts that elicit accurate and relevant answers from AI systems.\n",
      "5. **Content generation**: Using Prompt Engineering to create high-quality content, such as articles, stories, or dialogues.\n",
      "\n",
      "In conclusion, Prompt Engineering is a vital aspect of AI development, as it enables the creation of more effective, efficient, and user-friendly AI systems. By mastering the art of Prompt Engineering, developers can unlock the full potential of AI and create more intelligent, interactive, and helpful systems that improve human life.\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_str = simple_prompt_str | model | str_output_parser\n",
    "\n",
    "# Result\n",
    "response = chain_str.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fef2c",
   "metadata": {},
   "source": [
    "With Chat Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "0fa5ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is a relatively new field that has gained significant attention in recent years, especially with the rise of large language models and AI chatbots. It refers to the process of designing, crafting, and optimizing text prompts or inputs that are used to interact with artificial intelligence systems, such as language models, chatbots, or other machine learning models.\n",
      "\n",
      "The goal of prompt engineering is to elicit specific, accurate, and relevant responses from the AI system, while also ensuring that the prompts are clear, concise, and unambiguous. This involves understanding the strengths and limitations of the AI model, as well as the context and requirements of the task or application.\n",
      "\n",
      "Prompt engineering involves a range of techniques, including:\n",
      "\n",
      "1. **Prompt design**: Crafting well-structured and clear prompts that effectively communicate the task or question to the AI system.\n",
      "2. **Prompt optimization**: Refining and iterating on prompts to improve the accuracy, relevance, and quality of the AI system's responses.\n",
      "3. **Prompt tuning**: Adjusting prompts to adapt to specific contexts, domains, or tasks, and to mitigate potential biases or errors.\n",
      "4. **Prompt evaluation**: Assessing the effectiveness of prompts in eliciting desired responses from the AI system, and identifying areas for improvement.\n",
      "\n",
      "Effective prompt engineering can have a significant impact on the performance and usability of AI systems, enabling them to provide more accurate, informative, and helpful responses to users. It also has applications in areas such as natural language processing, human-computer interaction, and cognitive science.\n",
      "\n",
      "Some of the key benefits of prompt engineering include:\n",
      "\n",
      "* **Improved accuracy**: Well-designed prompts can help AI systems provide more accurate and relevant responses.\n",
      "* **Increased efficiency**: Effective prompts can reduce the need for multiple iterations or clarifications, saving time and effort.\n",
      "* **Enhanced user experience**: Clear and concise prompts can improve the overall user experience, making it easier for people to interact with AI systems.\n",
      "\n",
      "However, prompt engineering also presents some challenges, such as:\n",
      "\n",
      "* **Lack of standardization**: There is currently no standardized framework or guidelines for prompt engineering, making it a complex and nuanced field.\n",
      "* **Contextual dependencies**: Prompts can be highly context-dependent, requiring careful consideration of the specific task, domain, or application.\n",
      "* **Bias and fairness**: Prompts can inadvertently introduce biases or perpetuate existing social inequalities, highlighting the need for careful evaluation and mitigation strategies.\n",
      "\n",
      "Overall, prompt engineering is a rapidly evolving field that holds significant promise for improving the performance, usability, and overall effectiveness of AI systems.\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_str = chat_prompt_str | model | str_output_parser\n",
    "\n",
    "# Result\n",
    "response = chain_str.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ba0c0",
   "metadata": {},
   "source": [
    "##### 4.1.2. With JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e24915a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "json_output_parser = JsonOutputParser()\n",
    "json_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "baea63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt templates\n",
    "\n",
    "simple_prompt_json = PromptTemplate(\n",
    "    template=\"You are the best AI Engineer of the world. Answer the user query \\n {format_instruction} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":json_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_json = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI engineer of the world. Please response to the user as per query from user in proper JSON format.\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46c2ec",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "58650964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"definition\": \"Prompt Engineering is the process of designing and optimizing text prompts to effectively interact with language models, such as chatbots, virtual assistants, or other AI systems.\",\n",
      "  \"goal\": \"The primary goal of Prompt Engineering is to elicit specific, accurate, and relevant responses from the language model, while minimizing errors, ambiguities, and misunderstandings.\",\n",
      "  \"key_aspects\": [\n",
      "    \"Clear and concise language\",\n",
      "    \"Well-defined context\",\n",
      "    \"Specific and relevant keywords\",\n",
      "    \"Avoidance of ambiguity and uncertainty\",\n",
      "    \"Use of relevant examples or analogies\"\n",
      "  ],\n",
      "  \"benefits\": [\n",
      "    \"Improved accuracy and relevance of responses\",\n",
      "    \"Increased efficiency and effectiveness of language model interactions\",\n",
      "    \"Enhanced user experience and satisfaction\",\n",
      "    \"Better handling of complex and nuanced queries\"\n",
      "  ],\n",
      "  \"applications\": [\n",
      "    \"Chatbots and virtual assistants\",\n",
      "    \"Language translation and localization\",\n",
      "    \"Text summarization and generation\",\n",
      "    \"Sentiment analysis and opinion mining\",\n",
      "    \"Question answering and knowledge retrieval\"\n",
      "  ],\n",
      "  \"challenges\": [\n",
      "    \"Dealing with linguistic and cultural nuances\",\n",
      "    \"Handling ambiguity, uncertainty, and context-dependent queries\",\n",
      "    \"Ensuring consistency and coherence in responses\",\n",
      "    \"Mitigating biases and errors in language models\",\n",
      "    \"Continuously updating and refining prompts to adapt to evolving language models and user needs\"\n",
      "  ],\n",
      "  \"best_practices\": [\n",
      "    \"Conduct thorough user research and testing\",\n",
      "    \"Use clear, concise, and consistent language\",\n",
      "    \"Provide relevant context and examples\",\n",
      "    \"Test and refine prompts iteratively\",\n",
      "    \"Monitor and analyze user feedback and response data\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_json = simple_prompt_json | model\n",
    "\n",
    "# Result\n",
    "response = chain_json.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a1f02",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "b756a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"response\": {\n",
      "    \"definition\": \"Prompt Engineering is the process of designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models, such as chatbots, virtual assistants, or other AI systems.\",\n",
      "    \"key_aspects\": [\n",
      "      \"Understanding the capabilities and limitations of the language model\",\n",
      "      \"Defining clear and specific goals for the prompt\",\n",
      "      \"Crafting well-structured and unambiguous prompts\",\n",
      "      \"Testing and refining prompts to achieve desired outcomes\"\n",
      "    ],\n",
      "    \"applications\": [\n",
      "      \"Improving chatbot conversations\",\n",
      "      \"Enhancing language translation accuracy\",\n",
      "      \"Optimizing text summarization and generation\",\n",
      "      \"Developing more effective virtual assistants\"\n",
      "    ],\n",
      "    \"benefits\": [\n",
      "      \"Increased accuracy and relevance of responses\",\n",
      "      \"Improved user experience and engagement\",\n",
      "      \"Enhanced efficiency and productivity\",\n",
      "      \"Better decision-making and insight generation\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_json = chat_prompt_json | model\n",
    "\n",
    "# Result\n",
    "response = chain_json.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7f596",
   "metadata": {},
   "source": [
    "##### 4.1.3. With XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ef7817cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "xml_output_parser = XMLOutputParser()\n",
    "xml_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "c5d3765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt templates\n",
    "\n",
    "simple_prompt_xml = PromptTemplate(\n",
    "    template=\"You are the best AI Engineer of the world. Answer the user query \\n {format_instruction} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":xml_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_xml = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI engineer of the world. Please response to the user as per query from user in proper XML format.\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91665e24",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d15f5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>\n",
      "  <prompt_engineering>\n",
      "    <definition>Prompt engineering is the process of designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models like myself.</definition>\n",
      "    <importance>Prompt engineering is crucial in natural language processing (NLP) as it helps to improve the performance and reliability of language models, enabling them to better understand the context and intent behind a given prompt.</importance>\n",
      "    <techniques>\n",
      "      <technique>Well-defined prompts</technique>\n",
      "      <technique>Clear and concise language</technique>\n",
      "      <technique>Specific keywords and phrases</technique>\n",
      "      <technique>Contextual information</technique>\n",
      "    </techniques>\n",
      "    <applications>\n",
      "      <application>Chatbots and virtual assistants</application>\n",
      "      <application>Language translation and localization</application>\n",
      "      <application>Text summarization and generation</application>\n",
      "      <application>Sentiment analysis and opinion mining</application>\n",
      "    </applications>\n",
      "  </prompt_engineering>\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_xml = simple_prompt_xml | model\n",
    "\n",
    "# Result\n",
    "response = chain_xml.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f16595",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0dcfd79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<response>\n",
      "  <prompt>Introduction to Prompt Engineering</prompt>\n",
      "  <description>Prompt engineering is a subfield of natural language processing (NLP) that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models.</description>\n",
      "  <key_points>\n",
      "    <point>Definition: Prompt engineering involves crafting input text that guides the language model to produce desired outputs.</point>\n",
      "    <point>Goals: The primary goals of prompt engineering are to improve the performance, accuracy, and reliability of language models.</point>\n",
      "    <point>Techniques: Prompt engineers use various techniques, such as prompt templating, priming, and fine-tuning, to optimize prompts for specific tasks and models.</point>\n",
      "    <point>Applications: Prompt engineering has numerous applications, including text classification, sentiment analysis, question answering, and text generation.</point>\n",
      "  </key_points>\n",
      "  <benefits>\n",
      "    <benefit>Improved accuracy: Well-designed prompts can significantly improve the accuracy of language model outputs.</benefit>\n",
      "    <benefit>Increased efficiency: Effective prompts can reduce the need for extensive training data and computational resources.</benefit>\n",
      "    <benefit>Enhanced reliability: Prompt engineering can help mitigate biases and errors in language model responses.</benefit>\n",
      "  </benefits>\n",
      "  <future_directions>\n",
      "    <direction>Research: Ongoing research in prompt engineering focuses on developing more sophisticated techniques for prompt optimization and evaluation.</direction>\n",
      "    <direction>Applications: Prompt engineering is expected to play a crucial role in the development of more advanced NLP systems and applications.</direction>\n",
      "  </future_directions>\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_xml = chat_prompt_xml | model\n",
    "\n",
    "# Result\n",
    "response = chain_xml.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13802810",
   "metadata": {},
   "source": [
    "**Conclusion: With ChatPromptTemplate, the response is much cleaner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b4a43",
   "metadata": {},
   "source": [
    "##### 4.1.4. With CommaSeparatedListOutputParser (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "573ac48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the object\n",
    "csv_output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "59594c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4d143b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt templates\n",
    "\n",
    "simple_prompt_csv = PromptTemplate(\n",
    "    template=\"You are the best AI Engineer of the world. Answer the user query \\n {format_instruction} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":csv_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_csv = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI engineer of the world. Please response to the user as per query from user in proper CSV format.\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f312754",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "744cdf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering, prompt design, natural language processing, language model fine-tuning, human-computer interaction, conversational AI, dialogue systems, text generation, language understanding, machine learning, AI safety, adversarial testing, robustness evaluation, explainability methods, transparency techniques, human-centered design, user experience, cognitive architectures, decision-making models, cognitive biases, human factors, evaluation metrics, performance optimization, knowledge graph embedding, semantic search, question answering, text classification, sentiment analysis, named entity recognition, part-of-speech tagging, dependency parsing, coreference resolution, information retrieval, knowledge discovery, data mining, human-language technology, cognitive computing, artificial general intelligence, neural networks, deep learning, transformer models, attention mechanisms, language model architectures, transfer learning, few-shot learning, meta-learning, multimodal learning, human-AI collaboration, explainable AI, trustworthy AI, fair AI, accountable AI, transparent AI, ethical AI, responsible AI, AI for social good, AI for humanity, human-centered AI, value-aligned AI, beneficial AI, safe AI, robust AI, reliable AI, secure AI, private AI, explainable machine learning, model interpretability, model explainability, model transparency, model fairness, model accountability, model robustness, model reliability, model security, model privacy, human-AI trust, human-AI understanding, human-AI communication, human-AI collaboration, human-AI teamwork, human-AI partnership, human-AI symbiosis, human-AI mutual understanding, human-AI cooperative problem-solving, human-AI joint decision-making, human-AI shared control, human-AI adaptive systems, human-AI resilient systems, human-AI flexible systems, human-AI scalable systems, human-AI autonomous systems, human-AI hybrid systems, human-AI cyber-physical systems, human-AI socio-technical systems, human-AI complex systems, human-AI dynamic systems, human-AI nonlinear systems, human-AI chaotic systems, human-AI self-organizing systems, human-AI swarm intelligence, human-AI collective intelligence, human-AI distributed intelligence, human-AI decentralized intelligence, human-AI edge intelligence, human-AI fog intelligence, human-AI cloud intelligence, human-AI cognitive intelligence, human-AI artificial intelligence, human-AI machine intelligence, human-AI deep intelligence, human-AI narrow intelligence, human-AI general intelligence, human-AI superintelligence, human-AI singularity, human-AI intelligence explosion, human-AI technological singularity, human-AI existential risk, human-AI global risk, human-AI catastrophic risk, human-AI apocalyptic risk, human-AI human extinction, human-AI AI takeover, human-AI robot uprising, human-AI machine uprising, human-AI artificial general intelligence, human-AI superintelligent machines, human-AI autonomous machines, human-AI self-aware machines, human-AI conscious machines, human-AI sentient machines, human-AI intelligent machines, human-AI cognitive machines, human-AI rational machines, human-AI decision-making machines, human-AI problem-solving machines, human-AI learning machines, human-AI adaptive machines, human-AI autonomous systems, human-AI hybrid systems, human-AI cyber-physical systems, human-AI socio-technical systems, human-AI complex systems, human-AI dynamic systems, human-AI nonlinear systems, human-AI chaotic systems, human-AI self-organizing systems, human-AI swarm intelligence, human-AI collective intelligence, human-AI distributed intelligence, human-AI decentralized intelligence, human-AI edge intelligence, human-AI fog intelligence, human-AI cloud intelligence, human-AI cognitive intelligence, human-AI artificial intelligence, human-AI machine intelligence, human-AI deep intelligence, human-AI narrow intelligence, human-AI general intelligence, human-AI superintelligence, human-AI singularity, human-AI intelligence explosion, human-AI technological singularity, human-AI existential risk, human-AI global risk, human-AI catastrophic risk, human-AI apocalyptic risk, human-AI human extinction, human-AI AI takeover, human-AI robot uprising, human-AI machine uprising, human-AI artificial general intelligence, human-AI superintelligent machines, human-AI autonomous machines, human-AI self-aware machines, human-AI conscious machines, human-AI sentient machines, human-AI intelligent machines, human-AI cognitive machines, human-AI rational machines, human-AI decision-making machines, human-AI problem-solving machines, human-AI learning machines, human-AI adaptive machines.\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_csv = simple_prompt_csv | model\n",
    "\n",
    "# Result\n",
    "response = chain_csv.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb36d343",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fec6c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Category\",\"Description\",\"Key Points\"\n",
      "\"Introduction\",\"Prompt engineering is a subfield of natural language processing (NLP) that focuses on designing and optimizing text prompts to elicit specific responses from language models.\",\"Definition, Importance, Applications\"\n",
      "\"Definition\",\"Prompt engineering involves crafting input text that guides the language model to generate desired outputs, taking into account the model's strengths, weaknesses, and biases.\",\"Input Text, Language Model, Output\"\n",
      "\"Importance\",\"Well-designed prompts can significantly improve the performance and reliability of language models, enabling them to better understand the context and generate more accurate and relevant responses.\",\"Performance, Reliability, Context Understanding\"\n",
      "\"Applications\",\"Prompt engineering has various applications, including chatbots, virtual assistants, language translation, text summarization, and content generation.\",\"Chatbots, Virtual Assistants, Language Translation, Text Summarization, Content Generation\"\n",
      "\"Techniques\",\"Prompt engineers use various techniques, such as priming, chaining, and gradient-based methods, to optimize prompts and improve model performance.\",\"Priming, Chaining, Gradient-Based Methods\"\n",
      "\"Challenges\",\"Prompt engineering faces challenges, including prompt sensitivity, overfitting, and the need for large amounts of training data.\",\"Prompt Sensitivity, Overfitting, Training Data\"\n",
      "\"Future Directions\",\"Future research in prompt engineering may focus on developing more robust and generalizable prompts, improving model interpretability, and exploring applications in multimodal and multilingual settings.\",\"Robust Prompts, Model Interpretability, Multimodal Settings, Multilingual Settings\"\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_csv = chat_prompt_csv | model\n",
    "\n",
    "# Result\n",
    "response = chain_csv.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293a107",
   "metadata": {},
   "source": [
    "**Conclusion: CSV format is not properly coming with simple prompt. ChatPromptTemplate is best choice here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e6a95",
   "metadata": {},
   "source": [
    "##### 4.1.5. With PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "20f4685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Pydantic class\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class question(BaseModel):\n",
    "    heading: str = Field(description=\"header of the answer to the query.\")\n",
    "    details: str = Field(description=\"Detailed answer of the query.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c1f2be45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"heading\": {\"description\": \"header of the answer to the query.\", \"title\": \"Heading\", \"type\": \"string\"}, \"details\": {\"description\": \"Detailed answer of the query.\", \"title\": \"Details\", \"type\": \"string\"}}, \"required\": [\"heading\", \"details\"]}\\n```'"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "pydantic_output_parser = PydanticOutputParser(pydantic_object=question)\n",
    "\n",
    "pydantic_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e6a06df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt templates\n",
    "\n",
    "simple_prompt_pydantic = PromptTemplate(\n",
    "    template=\"You are the best AI Engineer of the world. Answer the user query \\n {format_instruction} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":pydantic_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_pydantic = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI engineer of the world. Please response to the user as per {query} from user \\n in proper format as given in {format_instruction}.\"),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instruction = pydantic_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a4fe9",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "66c19d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"heading\": \"Introduction to Prompt Engineering\",\n",
      "  \"details\": \"Prompt engineering is a subfield of natural language processing (NLP) that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models. It involves understanding how language models process and respond to input prompts, and using that knowledge to craft high-quality prompts that achieve desired outcomes. Prompt engineering has applications in areas such as chatbots, virtual assistants, language translation, and text summarization. By carefully designing prompts, developers can improve the performance and reliability of language models, and create more effective and engaging user experiences.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pydantic = simple_prompt_pydantic | model\n",
    "\n",
    "# Result\n",
    "response = chain_pydantic.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389999be",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "21b325ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"heading\": \"Introduction to Prompt Engineering\",\n",
      "  \"details\": \"Prompt engineering is a subfield of natural language processing (NLP) that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models. It involves crafting input text that guides the model to produce desired outputs, taking into account the model's strengths, weaknesses, and biases. Prompt engineering is crucial in various applications, including chatbots, virtual assistants, language translation, and text summarization. By carefully designing prompts, developers can improve the performance and reliability of language models, enabling them to better understand and respond to user queries.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pydantic = chat_prompt_pydantic | model\n",
    "\n",
    "# Result\n",
    "response = chain_pydantic.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041932d3",
   "metadata": {},
   "source": [
    "##### 4.1.6. With YamlOutputParser (Using Pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "4c41aafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a YAML instance that conforms to the given JSON schema below.\\n\\n# Examples\\n## Schema\\n```\\n{\"title\": \"Players\", \"description\": \"A list of players\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Player\"}, \"definitions\": {\"Player\": {\"title\": \"Player\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"Player name\", \"type\": \"string\"}, \"avg\": {\"title\": \"Avg\", \"description\": \"Batting average\", \"type\": \"number\"}}, \"required\": [\"name\", \"avg\"]}}}\\n```\\n## Well formatted instance\\n```\\n- name: John Doe\\n  avg: 0.3\\n- name: Jane Maxfield\\n  avg: 1.4\\n```\\n\\n## Schema\\n```\\n{\"properties\": {\"habit\": { \"description\": \"A common daily habit\", \"type\": \"string\" }, \"sustainable_alternative\": { \"description\": \"An environmentally friendly alternative to the habit\", \"type\": \"string\"}}, \"required\": [\"habit\", \"sustainable_alternative\"]}\\n```\\n## Well formatted instance\\n```\\nhabit: Using disposable water bottles for daily hydration.\\nsustainable_alternative: Switch to a reusable water bottle to reduce plastic waste and decrease your environmental footprint.\\n```\\n\\nPlease follow the standard YAML formatting conventions with an indent of 2 spaces and make sure that the data types adhere strictly to the following JSON schema:\\n```\\n{\"properties\": {\"heading\": {\"description\": \"header of the answer to the query.\", \"title\": \"Heading\", \"type\": \"string\"}, \"details\": {\"description\": \"Detailed answer of the query.\", \"title\": \"Details\", \"type\": \"string\"}}, \"required\": [\"heading\", \"details\"]}\\n```\\n\\nMake sure to always enclose the YAML output in triple backticks (```). Please do not add anything other than valid YAML output!'"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "yaml_output_parser = YamlOutputParser(pydantic_object=question)\n",
    "yaml_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a452947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt templates\n",
    "\n",
    "simple_prompt_yaml = PromptTemplate(\n",
    "    template=\"You are the best AI Engineer of the world. Answer the user query \\n {format_instruction} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":yaml_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_yaml = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI engineer of the world. Please response to the user as per {query} from user \\n in proper format as given in {format_instruction}.\"),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instruction = yaml_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a5af22",
   "metadata": {},
   "source": [
    "With Simple prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "663cfcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "heading: Introduction to Prompt Engineering\n",
      "details: Prompt engineering is a subfield of natural language processing that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models. It involves carefully crafting the input text, or prompt, to guide the model's output and achieve a desired outcome, such as generating text, answering questions, or completing tasks. Effective prompt engineering requires a deep understanding of language models, their strengths and limitations, and the nuances of language itself.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_yaml = simple_prompt_yaml | model\n",
    "\n",
    "# Result\n",
    "response = chain_yaml.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50cbf0",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d5546939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "heading: Introduction to Prompt Engineering\n",
      "details: Prompt Engineering is a subfield of natural language processing (NLP) that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models. It involves understanding how language models process and respond to input prompts, and using this knowledge to craft high-quality prompts that achieve desired outcomes. Prompt engineering has applications in areas such as chatbots, virtual assistants, and language translation, where well-designed prompts can significantly improve the performance and usability of these systems.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_yaml = chat_prompt_yaml | model\n",
    "\n",
    "# Result\n",
    "response = chain_yaml.invoke({\"query\": \"Can you tell me about 'Prompt Engineering'?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19341e4d",
   "metadata": {},
   "source": [
    "##### 4.1.7. With PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "043be61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Data\n",
    "data = {\n",
    "    \"Fruits\": [\"Apple\", \"Mango\", \"Banana\"],\n",
    "    \"Price\": [30, 45, 50],\n",
    "    \"Quantity\":[100, 200, 300]\n",
    "\n",
    "}\n",
    "\n",
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "87e5ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\\n1. The column names are limited to the possible columns below.\\n2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\\n3. Remember that arrays are optional and not necessarily required.\\n4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\\n\\nAs an example, for the formats:\\n1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\\n2. String \"row:1\" is a well-formatted instance which gets row 1.\\n3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\\n4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\\n5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\\n6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\\n7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\\n\\nHere are the possible columns:\\n```\\nFruits, Price, Quantity\\n```\\n'"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "pd_output_parser = PandasDataFrameOutputParser(dataframe=df_data)\n",
    "pd_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ed58268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt template\n",
    "simple_prompt_pd = PromptTemplate(\n",
    "    template=(\"You are the best AI Engineer of the world. Return Exactly one operation that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid Dataframe format. Do not return any additional text.\"),\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": pd_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_prompt_pd = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI Engineer of the world. Return exactly one operation string that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid Dataframe format. Do not return any additional text.\"),\n",
    "        (\"user\", \"\"),\n",
    "    ]\n",
    ").partial(format_instructions = pd_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca46fc0",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "16ffa221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during parsing The maximum index 3 exceeds the maximum index of                     the Pandas DataFrame 2.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Ensure the dataframe adhere to the format correctly.\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pd = simple_prompt_pd | model | pd_output_parser\n",
    "\n",
    "# Result\n",
    "try:\n",
    "    response_df = chain_pd.invoke({})\n",
    "    print(\"Parsed Dataframe \\n\", response_df)\n",
    "    print(\"Dataframe Info: \\n\", response_df.info())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during parsing {e}\")\n",
    "    print(\"Ensure the dataframe adhere to the format correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8726f1a",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "d6a37c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during parsing The maximum index 3 exceeds the maximum index of                     the Pandas DataFrame 2.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Ensure the dataframe adhere to the format correctly.\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pd = chat_prompt_pd | model | pd_output_parser\n",
    "\n",
    "# Result\n",
    "try:\n",
    "    response_df = chain_pd.invoke({})\n",
    "    print(\"Parsed Dataframe \\n\", response_df)\n",
    "    print(\"Dataframe Info: \\n\", response_df.info())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during parsing {e}\")\n",
    "    print(\"Ensure the dataframe adhere to the format correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff43aa",
   "metadata": {},
   "source": [
    "**Conclusion: Why it failed? Because, pd_output_parser.get_format_instructions() returns a long string that includes the mini-grammar and examples of valid requests. Even though I didn’t write any examples yourself, the parser supplies them. Now as I asked to return \"Only ONE operation\" and not the exact one, it randomly picks something from those examples, for which I did not define the index. Let me now try it with OutputFixingParser.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d916e4",
   "metadata": {},
   "source": [
    "##### 4.1.8. With OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "902b9356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\\n1. The column names are limited to the possible columns below.\\n2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\\n3. Remember that arrays are optional and not necessarily required.\\n4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\\n\\nAs an example, for the formats:\\n1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\\n2. String \"row:1\" is a well-formatted instance which gets row 1.\\n3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\\n4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\\n5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\\n6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\\n7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\\n\\nHere are the possible columns:\\n```\\nFruits, Price, Quantity\\n```\\n'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "fixing_output_parser = OutputFixingParser.from_llm(parser=pd_output_parser, llm=model)\n",
    "fixing_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "aef21c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt template\n",
    "simple_prompt_pd = PromptTemplate(\n",
    "    template=(\"You are the best AI Engineer of the world. Return exactly ONE operation string that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid Dataframe format. Do not return any additional text.\"),\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": fixing_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_prompt_pd = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI Engineer of the world. Return exactly ONE operation string that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid Dataframe format. Do not return any additional text.\"),\n",
    "        (\"user\", \"\"),\n",
    "    ]\n",
    ").partial(format_instructions = fixing_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c27ca",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "59ced07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Dataframe \n",
      " {'mean': np.float64(41.666666666666664)}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pd = simple_prompt_pd | model | fixing_output_parser\n",
    "\n",
    "# Result\n",
    "try:\n",
    "    response_df = chain_pd.invoke({})\n",
    "    print(\"Parsed Dataframe \\n\", response_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during parsing {e}\")\n",
    "    print(\"Ensure the dataframe adhere to the format correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442135",
   "metadata": {},
   "source": [
    "With Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ce949810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Dataframe \n",
      " {'mean': np.float64(41.666666666666664)}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pd = chat_prompt_pd | model | fixing_output_parser\n",
    "\n",
    "# Result\n",
    "try:\n",
    "    response_df = chain_pd.invoke({})\n",
    "    print(\"Parsed Dataframe \\n\", response_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during parsing {e}\")\n",
    "    print(\"Ensure the dataframe adhere to the format correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad143fc0",
   "metadata": {},
   "source": [
    "**Conclusion: Why it worked? Because, OutputFixingParser worked as a repair layer. It internally derived the error, reprompted with possible valid operations. So the issue did not reoccurred.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9e4af",
   "metadata": {},
   "source": [
    "##### 4.1.9. With RetryWithErrorOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "da5fcac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\\n1. The column names are limited to the possible columns below.\\n2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\\n3. Remember that arrays are optional and not necessarily required.\\n4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\\n\\nAs an example, for the formats:\\n1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\\n2. String \"row:1\" is a well-formatted instance which gets row 1.\\n3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\\n4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\\n5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\\n6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\\n7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\\n\\nHere are the possible columns:\\n```\\nFruits, Price, Quantity\\n```\\n'"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RunnableLambda\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define the object\n",
    "retry_output_parser = RetryWithErrorOutputParser.from_llm(parser=pd_output_parser, llm=model)\n",
    "retry_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "7456645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt template\n",
    "simple_prompt_pd = PromptTemplate(\n",
    "    template=(\"You are the best AI Engineer of the world. Return exactly ONE operation string that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid Dataframe format. Do not return any additional text.\"),\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": pd_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_prompt_pd = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI Engineer of the world. Return exactly ONE operation string that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid Dataframe format. Do not return any additional text.\"),\n",
    "        (\"user\", \"\"),\n",
    "    ]\n",
    ").partial(format_instructions = pd_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775782d",
   "metadata": {},
   "source": [
    "With Simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "a75866b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Dataframe \n",
      " {'mean': np.float64(41.666666666666664)}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pd = simple_prompt_pd | model | str_output_parser | RunnableLambda(\n",
    "    lambda text: retry_output_parser.parse_with_prompt(\n",
    "        text, \n",
    "        simple_prompt_pd.format_prompt()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Result\n",
    "try:\n",
    "    response_df = chain_pd.invoke({})\n",
    "    print(\"Parsed Dataframe \\n\", response_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during parsing {e}\")\n",
    "    print(\"Ensure the dataframe adhere to the format correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741ef25",
   "metadata": {},
   "source": [
    "With Chat prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "eda3f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Dataframe \n",
      " {'mean': np.float64(41.666666666666664)}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_pd = chat_prompt_pd | model | str_output_parser | RunnableLambda(\n",
    "    lambda text: retry_output_parser.parse_with_prompt(\n",
    "        text, \n",
    "        chat_prompt_pd.format_prompt()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Result\n",
    "try:\n",
    "    response_df = chain_pd.invoke({})\n",
    "    print(\"Parsed Dataframe \\n\", response_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during parsing {e}\")\n",
    "    print(\"Ensure the dataframe adhere to the format correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab47aa",
   "metadata": {},
   "source": [
    "**Conclusion: OutputFixingParser just take the bad LLM output and ask to edit it to fit the schema. RetryWithErrorOutputParser pass the error and the original query again and tell to retry from scratch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d80fc",
   "metadata": {},
   "source": [
    "##### 4.1.10. With DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "88acb4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 2023-07-04T14:30:00.000000Z, 1999-12-31T23:59:59.999999Z, 2025-01-01T00:00:00.000000Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_output_parser = DatetimeOutputParser()\n",
    "\n",
    "datetime_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "01dd09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt template\n",
    "simple_prompt_datetime = PromptTemplate(\n",
    "    template=(\"You are the best AI Engineer of the world. Return response for the {query} that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid datetime format. Do not return any additional text.\"),\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": datetime_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_prompt_datetime = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI Engineer of the world. Return response for the {query} that conforms to {format_instructions} \\n\" \\\n",
    "              \"You must always return valid datetime format. Do not return any additional text.\"),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions = datetime_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ca7f5",
   "metadata": {},
   "source": [
    "With simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "0f50d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-21 18:45:00\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_datetime = simple_prompt_datetime | model | datetime_output_parser\n",
    "\n",
    "# Result\n",
    "response = chain_datetime.invoke({\"query\": \"When was 'attention all you need' paper published?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6a561",
   "metadata": {},
   "source": [
    "With chat prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "256169d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951-08-18 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_datetime = chat_prompt_datetime | model | datetime_output_parser\n",
    "\n",
    "# Result\n",
    "response = chain_datetime.invoke({\"query\": \"What was the date of inauguration of first IIT in India?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbb5cc",
   "metadata": {},
   "source": [
    "**Conclusion: This is not a RAG solution. LLM is only publishing the year based on its training and 'assuming' the time which is not known by it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b0641",
   "metadata": {},
   "source": [
    "##### 4.1.11. With StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "71c2e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Response schema\n",
    "response_schema = [\n",
    "    ResponseSchema(name=\"Header\", description=\"title of the subject.\"),\n",
    "    ResponseSchema(name=\"Description\", description=\"Detailed description of the subject.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ef233b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"Header\": string  // title of the subject.\\n\\t\"Description\": string  // Detailed description of the subject.\\n}\\n```'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the object\n",
    "structured_output_parser = StructuredOutputParser.from_response_schemas(response_schemas=response_schema)\n",
    "structured_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "492ecf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt template\n",
    "simple_prompt_structured = PromptTemplate(\n",
    "    template=(\"You are the best AI Engineer of the world. Return response for the {query} that conforms to {format_instructions} \\n\"),\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": structured_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chat_prompt_structured = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are the best AI Engineer of the world. Return response for the {query} that conforms to {format_instructions} \\n\"),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions = structured_output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df29ec4",
   "metadata": {},
   "source": [
    "With simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "60821cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Header': 'Prompt Engineering', 'Description': \"Prompt engineering is a subfield of natural language processing (NLP) and artificial intelligence (AI) that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models. It involves crafting input text that is clear, concise, and well-defined to achieve a particular goal or outcome. Prompt engineering is crucial in various applications, including chatbots, virtual assistants, language translation, text summarization, and content generation. The process typically involves analyzing the task requirements, understanding the language model's capabilities and limitations, and iteratively refining the prompt to improve the quality and relevance of the response. Effective prompt engineering can significantly enhance the performance and usability of language models, enabling them to better understand user intent, provide more accurate answers, and generate high-quality content.\"}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_structured = simple_prompt_structured | model | structured_output_parser\n",
    "\n",
    "# Result\n",
    "response = chain_structured.invoke({\"query\": \"Tell me about 'Prompt Engineering'\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f7198",
   "metadata": {},
   "source": [
    "With Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "298e8835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Header': 'Prompt Engineering', 'Description': 'Prompt engineering is a subfield of natural language processing (NLP) and artificial intelligence (AI) that focuses on designing and optimizing text prompts to elicit specific, accurate, and relevant responses from language models. It involves crafting input text that is clear, concise, and well-defined to achieve a desired outcome, such as generating text, answering questions, or completing tasks. Prompt engineering requires a deep understanding of language models, their strengths and limitations, and the nuances of human language. The goal of prompt engineering is to create prompts that are effective, efficient, and scalable, and that can be used to improve the performance of language models in a wide range of applications, from chatbots and virtual assistants to language translation and text summarization. By carefully designing and refining prompts, developers can unlock the full potential of language models and create more accurate, informative, and engaging interactions between humans and machines.'}\n"
     ]
    }
   ],
   "source": [
    "# Chaining\n",
    "chain_structured = chat_prompt_structured | model | structured_output_parser\n",
    "\n",
    "# Result\n",
    "response = chain_structured.invoke({\"query\": \"Tell me about 'Prompt Engineering'\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_session_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
